{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Feature Engineering Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Engineer features for Regression models\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousePricing.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate a list with variables to engineer\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "\n",
        "\n",
        "* Feature Engineering Transformers\n",
        "  * Ordinal categorical encoding: `['KitchenQual', 'GarageFinish', 'BsmtFinType1', 'BsmtExposure']`\n",
        "  * Numerical Transformation: YeoJohnsonTransformer `['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']`\n",
        "  * Smart Correlation Selection: `['1stFlrSF', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'YearRemodAdd']`\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to make the parent of the current directory the new current directory.\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2ELZj83tF1g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('outputs/datasets/collection/HousePricing.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNJOqym1a38e"
      },
      "source": [
        "### Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-WRjItbiOs6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.selection import DropFeatures\n",
        "pipeline = Pipeline([\n",
        "      ('Median', MeanMedianImputer(imputation_method='median', \n",
        "                                   variables=['2ndFlrSF', 'BedroomAbvGr', 'GarageYrBlt', \n",
        "                                              'LotFrontage', 'MasVnrArea']\n",
        "                                              )),\n",
        "      ('CategoricalImputer', CategoricalImputer(imputation_method='missing', \n",
        "                                                fill_value='No Record', \n",
        "                                                variables=['BsmtFinType1','GarageFinish']\n",
        "                                                )),\n",
        "      ('Drop', DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF']))\n",
        "])\n",
        "pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = pipeline.transform(TrainSet) , pipeline.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iue5e5GJ_vZg"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edx7E2Yr4sZ5"
      },
      "source": [
        "In feature engineering, you are interested to evaluate which potential transformation you could do in your variables\n",
        "* Take your notes in your separate spreadsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyi3gi2-_q1j"
      },
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqEHqNwyrucq"
      },
      "source": [
        "## Custom function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuEsBAljDsLO"
      },
      "source": [
        "We studied this custom function in the feature-engine lesson. That will help you with the feature engineering process.\n",
        "* Do not worry if you need help understanding the full code at first, as it is expected you will take some time to absorb the use case.\n",
        "* At this moment, what matters is to understand the function objective and how you can use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "masShIoqzf2b"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
        "    \"\"\"\n",
        "    - used for quick feature engineering on numerical and categorical variables\n",
        "    to decide which transformation can better transform the distribution shape\n",
        "    - Once transformed, use a reporting tool, like ydata-profiling, to evaluate distributions\n",
        "    \"\"\"\n",
        "    check_missing_values(df)\n",
        "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
        "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "\n",
        "    # Loop in each variable and engineer the data according to the analysis type\n",
        "    df_feat_eng = pd.DataFrame([])\n",
        "    for column in df.columns:\n",
        "        # create additional columns (column_method) to apply the methods\n",
        "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "        for method in list_column_transformers:\n",
        "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "\n",
        "        # Apply transformers in respective column_transformers\n",
        "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
        "            analysis_type, df_feat_eng, column)\n",
        "\n",
        "        # For each variable, assess how the transformations perform\n",
        "        transformer_evaluation(\n",
        "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "    return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "    \"\"\" Check analysis type \"\"\"\n",
        "    if analysis_type is None:\n",
        "        raise SystemExit(\n",
        "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "    if analysis_type not in allowed_types:\n",
        "        raise SystemExit(\n",
        "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
        "\n",
        "\n",
        "def check_missing_values(df):\n",
        "    if df.isna().sum().sum() != 0:\n",
        "        raise SystemExit(\n",
        "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
        "    if analysis_type == 'numerical':\n",
        "        list_column_transformers = [\n",
        "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
        "\n",
        "    elif analysis_type == 'ordinal_encoder':\n",
        "        list_column_transformers = [\"ordinal_encoder\"]\n",
        "\n",
        "    elif analysis_type == 'outlier_winsorizer':\n",
        "        list_column_transformers = ['iqr']\n",
        "\n",
        "    return list_column_transformers\n",
        "\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
        "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
        "\n",
        "    if analysis_type == 'numerical':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    elif analysis_type == 'outlier_winsorizer':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    elif analysis_type == 'ordinal_encoder':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    return df_feat_eng, list_applied_transformers\n",
        "\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "    # For each variable, assess how the transformations perform\n",
        "    print(f\"* Variable Analyzed: {column}\")\n",
        "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "    for col in [column] + list_applied_transformers:\n",
        "\n",
        "        if analysis_type != 'ordinal_encoder':\n",
        "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        else:\n",
        "            if col == column:\n",
        "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
        "            else:\n",
        "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
        "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
        "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
        "    sns.boxplot(x=df[variable], ax=axes[2])\n",
        "\n",
        "    axes[0].set_title('Histogram')\n",
        "    axes[1].set_title('QQ Plot')\n",
        "    axes[2].set_title('Boxplot')\n",
        "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "    try:\n",
        "        encoder = OrdinalEncoder(encoding_method='arbitrary', \n",
        "                        variables=[f\"{column}_ordinal_encoder\"])\n",
        "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
        "\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # Winsorizer iqr\n",
        "    try:\n",
        "        disc = Winsorizer(\n",
        "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
        "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_iqr\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # LogTransformer base e\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_e\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
        "\n",
        "    # LogTransformer base 10\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_10\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
        "\n",
        "    # ReciprocalTransformer\n",
        "    try:\n",
        "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
        "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
        "\n",
        "    # PowerTransformer\n",
        "    try:\n",
        "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
        "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_power\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
        "\n",
        "    # BoxCoxTransformer\n",
        "    try:\n",
        "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
        "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_box_cox\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
        "\n",
        "    # YeoJohnsonTransformer\n",
        "    try:\n",
        "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
        "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yh2FMDd4wWZ"
      },
      "source": [
        "## Feature Engineering Spreadsheet Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Consider the notes taken in your spreadsheet summary. List the transformers you will use\n",
        "    * Categorical Encoding\n",
        "    * Numerical Transformation\n",
        "    * Smart Correlation Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-9iRH_ZEMoJ"
      },
      "source": [
        "## Dealing with Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GT8e9W_onJj"
      },
      "source": [
        "### Categorical Encoding - Ordinal: replaces categories with ordinal numbers "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwG_KMpOonJu"
      },
      "source": [
        "* Step 1: Select variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ii9nXtJonJv"
      },
      "outputs": [],
      "source": [
        "variables_engineering= ['KitchenQual', 'GarageFinish', 'BsmtFinType1', 'BsmtExposure']\n",
        "\n",
        "variables_engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t32melBMonJy"
      },
      "source": [
        "* Step 2: Create a separate DataFrame, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJJBWQlconJy"
      },
      "outputs": [],
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mk058LZonJz"
      },
      "source": [
        "* Step 3: Create engineered variables(s) by applying the transformation(s), assess engineered variables distribution and select the most suitable method for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKEuWXrtonJz"
      },
      "outputs": [],
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='ordinal_encoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfAiPd8DonJz"
      },
      "source": [
        "* For each variable, write your conclusion on how the transformation(s) look(s) to be effective.\n",
        "  * For all variables, the transformation is effective, since it converted categories to numbers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OrdinalEncoder(encoding_method='arbitrary', variables=variables_engineering)\n",
        "TrainSet = encoder.fit_transform(TrainSet)\n",
        "TestSet = encoder.transform(TestSet)\n",
        "\n",
        "print(\"* Categorical encoding - ordinal transformation done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkyO7KsuyG5A"
      },
      "source": [
        "### Numerical Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l4eVnHNyG5E"
      },
      "source": [
        "* Step 1: Select variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-dEF_P4yG5E"
      },
      "outputs": [],
      "source": [
        "variables_engineering = ['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']\n",
        "variables_engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUA_uA1_yG5I"
      },
      "source": [
        "* Step 2: Create a separate DataFrame, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrplTb39yG5I"
      },
      "outputs": [],
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQqqdvd3yG5J"
      },
      "source": [
        "* Step 3: Create engineered variables(s) by applying the transformation(s), assess engineered variables distribution and select the most suitable method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZXMUZgEyG5J"
      },
      "outputs": [],
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5TyFpY1yG5J"
      },
      "source": [
        "Conclusion on how the transformation(s) look(s) to be effective\n",
        "\n",
        "**1stFlrSF**\n",
        "\n",
        "  - **Original**: The histogram shows a right skew, the Q-Q plot indicates the distribution tails off more steeply than normal, and there are outliers apparent in the boxplot.\n",
        "\n",
        "  - **Logarithmic Transformation e:** The histogram looks more symmetric, indicating that the transformation has corrected some of the skewness. The Q-Q plot is more linear, especially in the central values, though there are deviations in the tails. The boxplot shows fewer outliers, suggesting improvement towards normality.\n",
        "  \n",
        "  - **Logarithmic Transformation 10:** Similar to the natural logarithm transformation, the histogram is more bell-shaped, the Q-Q plot looks linear for the central quantiles, and the boxplot shows a reduction in outliers. Both logarithmic transformations appear effective, but without specific values on the Q-Q plot, it's hard to say which is better.\n",
        "  \n",
        "  - **Reciprocal Transformation:** The histogram shows an extreme skew, the Q-Q plot exhibits strong nonlinearity, and the boxplot has a lot of spread in the data, indicating that this transformation is not appropriate for normalizing the data.\n",
        "\n",
        "  - **Power Transformation:** The histogram reveals a right skew, the Q-Q plot shows a nonlinear pattern, and the boxplot suggests the presence of outliers. This indicates that the power transformation has not normalized the data effectively.\n",
        "\n",
        "  - **Box-Cox Transformation:**  The histogram is fairly symmetric, the Q-Q plot demonstrates a mostly linear pattern, although there's some deviation in the tails, and the boxplot indicates fewer outliers. This transformation appears to have a substantial normalizing effect.\n",
        "\n",
        "  - **Yeo-Johnson Transformation:** The histogram is quite symmetric, the Q-Q plot follows the line closely with only slight deviations at the tails, and the boxplot shows a reasonable range with some outliers. This transformation seems to normalize the data well\n",
        "\n",
        "**Summary**\n",
        "\n",
        "All three logarithmic-based transformations (natural log, base 10 log, and Box-Cox) show significant improvement in normalizing the distribution. \n",
        "The Yeo-Johnson transformation seems to perform similarly to the Box-Cox.\n",
        "\n",
        "**LotArea**\n",
        "\n",
        "   - **Original**: Shows a right skewness, as we se by the long tail on the right in the histogram, the nonlinear pattern in the Q-Q plot, and the many outliers on the right in the boxplot.\n",
        "\n",
        "   - **Logarithmic Transformation e:** Still shows some right skewness but to a lesser extent. There are fewer outliers, and the Q-Q plot is closer to a straight line.\n",
        "  \n",
        "  - **Logarithmic Transformation 10:** Shows improvements similar to the log_e transformation but does not differ significantly from it in terms of normality.\n",
        "  \n",
        "  - **Reciprocal Transformation:** Leads to a left-skewed distribution, which is also not normal, as it is evident from the tail to the left in the histogram, the S-shaped Q-Q plot, and the presence of outliers in the boxplot.\n",
        "\n",
        "  - **Power Transformation:** Doesn't result in normality, as seen by the right skew in the histogram and the nonlinear Q-Q plot.\n",
        "\n",
        "  - **Box-Cox Transformation:** Seems to offer a significant improvement with a more symmetric histogram and a Q-Q plot that is more linear than the previous transformations.\n",
        "\n",
        "  - **Yeo-Johnson Transformation:** Shows similar improvements as the Box-Cox, with a fairly symmetric histogram and a reasonably linear Q-Q plot.\n",
        "\n",
        " \n",
        "**Summary**\n",
        "\n",
        "The Box-Cox and Yeo-Johnson transformations appear to have the most effective normalizing effect on the distribution. Both result in histograms that are approximately symmetric and have Q-Q plots that suggest resemblance to normal distribution, although the Yeo-Johnson transformation might have a slight edge due to fewer outliers in the boxplot.\n",
        "In conclusion the Yeo-Johnson transformation seems to be the best\n",
        "\n",
        "**LotFrontage**\n",
        "\n",
        "   - **Original**: The histogram shows a significant right skew, the Q-Q plot indicates substantial deviation from normality, particularly for larger values, and the boxplot displays many outliers.\n",
        "\n",
        "   - **Logarithmic Transformations (e and 10):** Both improved symmetry in the histograms and the Q-Q plots are closer to linear, especially for central values. The boxplots show fewer outliers compared to the original.\n",
        "  \n",
        "  - **Reciprocal Transformation:** The histogram is still right-skewed, and the Q-Q plot shows substantial deviations. The boxplot indicates the presence of extreme values.\n",
        "\n",
        "  - **Power Transformation:** It shows an improvement in the histogram symmetry but still some skewness is present. The Q-Q plot has noticeable deviations in the tails, and the boxplot indicates outliers.\n",
        "\n",
        "  - **Box-Cox Transformation:** The histogram is more symmetric than the original, the Q-Q plot shows smaller deviations, and the boxplot indicates a reduction in outliers, suggesting a more normal-like distribution.\n",
        "\n",
        "  - **Yeo-Johnson Transformation:**  Similar to the Box-Cox, the histogram is relatively symmetric, the Q-Q plot aligns more closely with the reference line, and the boxplot shows fewer outliers.\n",
        "\n",
        "\n",
        "**Summary**\n",
        "\n",
        "Both Box-Cox and Yeo-Johnson transformations seems to be the most effective in normalizing, indicated in the more symmetric histograms and the Q-Q plots which are closer to the reference line, implying a normal distribution more closely. Both are suitable choice.\n",
        "\n",
        "\n",
        "**GrLivArea**\n",
        "\n",
        "  - **Original:** The histogram shows right skewness, the Q-Q plot indicates heavy tails, and the boxplot shows outliers, implying it is not normally distributed.\n",
        "\n",
        "  - **Logarithmic Transformation e:** The histogram is more symmetric, the Q-Q plot is closer to the reference line, and the boxplot shows fewer outliers, indicating an improvement toward normality.\n",
        "\n",
        "  - **Logarithmic Transformation 10:** This transformation also yields a more bell-shaped histogram, a Q-Q plot that aligns well with the reference line for most of the distribution, and a boxplot with fewer outliers.\n",
        "\n",
        "  - **Reciprocal Transformation:** The histogram is very skewed, the Q-Q plot indicates non-normality, and the boxplot displays extreme outliers. This transformation does not appear to be suitable.\n",
        "\n",
        "  - **Power Transformation:** The histogram is more symmetric than the original, the Q-Q plot is closer to linear, though there's still some deviation, and the boxplot has outliers, suggesting some improvement but not optimal.\n",
        "\n",
        "  - **Box-Cox Transformation:** The histogram appears normally distributed, the Q-Q plot fits the reference line well except for the extreme values, and the boxplot shows a few outliers. This transformation significantly improves the normality.\n",
        "\n",
        "  - **Yeo-Johnson Transformation:** The histogram, Q-Q plot, and boxplot are similar to those of the Box-Cox transformation, suggesting this transformation also normalizes the data effectively.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "The Box-Cox and Yeo-Johnson transformations perform well, resulting in a distribution that is closer to normal for. Given the similarity in their performance, both would work.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yeo = vt.YeoJohnsonTransformer(variables=variables_engineering)\n",
        "TrainSet = yeo.fit_transform(TrainSet)\n",
        "TestSet = yeo.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_kMYDKU2yuT"
      },
      "source": [
        "### SmartCorrelatedSelection Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-pse1Ge2yub"
      },
      "source": [
        "* Create a separate DataFrame, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hnHWkNf2yub"
      },
      "outputs": [],
      "source": [
        "df_engineering = TrainSet.copy()\n",
        "df_engineering.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJsN5KNe2yuc"
      },
      "source": [
        "* Step 3: Create engineered variables(s) applying the transformation(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq-jWVT2e2v3"
      },
      "outputs": [],
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
        "\n",
        "corr_sel.fit_transform(df_engineering)\n",
        "corr_sel.correlated_feature_sets_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVQW3s0QfasQ"
      },
      "outputs": [],
      "source": [
        "corr_sel.features_to_drop_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZiCdjylhGP-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQSUo5fxnozU"
      },
      "source": [
        "# So what is the conclusion? :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOP2pVnJnwxS"
      },
      "source": [
        "The list below shows the transformations needed for feature engineering.\n",
        "  * You will add these steps to the ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9EtvPIPnpYb"
      },
      "source": [
        "\n",
        "Feature Engineering Transformers\n",
        "  * Ordinal categorical encoding: `['KitchenQual', 'GarageFinish', 'BsmtFinType1', 'BsmtExposure']`\n",
        "  * Numerical Transformation: YeoJohnsonTransformer `['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']`\n",
        "  * Smart Correlation Selection: `['1stFlrSF', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'YearRemodAdd']`\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
